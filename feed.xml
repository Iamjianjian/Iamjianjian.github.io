<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>sofiesJian</title>
    <description>Nothing # this means to ignore newlines until &quot;baseurl:&quot;
</description>
    <link>/</link>
    <atom:link href="/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Mon, 14 Jan 2019 20:53:44 +0800</pubDate>
    <lastBuildDate>Mon, 14 Jan 2019 20:53:44 +0800</lastBuildDate>
    <generator>Jekyll v3.8.5</generator>
    
      <item>
        <title>deep learning</title>
        <description>&lt;h2 id=&quot;日常review&quot;&gt;日常review&lt;/h2&gt;
&lt;p&gt;插入review，一开始我们要做分类，通过classification知道二元分类的时候强行用一样的covariance最终找到的funciton是线性的。之后我们尝试直接找到w，b，而不是先假设概率分布再通过极大拟然估计求分布。之后我们把一个二元分类，之前知道p(c|x)=&lt;script type=&quot;math/tex&quot;&gt;\frac{1}{1+e^{-z}}&lt;/script&gt;而z是线性的。
&lt;img src=&quot;/img/logisticRegression/z.png&quot; alt=&quot;z的表达式&quot; /&gt;
然后f是z的simog就是概率，data的概率相乘通过数学转换等价与于求cross entropy。然后通过gradient descent求最佳的function偏微分之后形式跟linear regression是一致的。之后对于多元分类，(老师没给出推到)说可以通过跟classification一样通过假设一样的covariance matrix，求到p{c|x}就是z做softmax得到的结果y（这里的的y是未知的他只是一个表达式）.最后用loss function也是跟二元的一样做cross entropy,之后就是求偏微分找最好的function了。&lt;/p&gt;

&lt;h2 id=&quot;three-steps&quot;&gt;three steps&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;/img/deepLearning/threeSteps.png&quot; alt=&quot;threeSteps&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;define-a-set-of-functions-也就是一个neuron-network&quot;&gt;define a set of functions 也就是一个neuron network&lt;/h3&gt;
&lt;p&gt;把logistic regression（也可以不用logistic）连接在一起，一个logistic regression就是一个neuron，所有连接起来就是一个neuron network。每个logistic regression都有自己的parameter(weight,bias)，所有这些parameter就是neuron network的parameter。至于怎么连接是手动连接的，要自己设计。例如fully connect feedforward network。
&lt;img src=&quot;/img/deepLearning/fullyconnectfeedforwardnetwork.png&quot; alt=&quot;fullyconnectfeedforwardnetwork&quot; /&gt;
我们定好一个neuron network的连接结构也就定好了一个function set，当我们定好了neuron network中每个logistic regression 的parameter ，那么我们的function就定下来了。通常用矩阵来做运算，这样可以用gpu加速。除了输入的data那一层和输出结果的那一层，中间的都是hiddenlayer。hidden对feature加工给最后一层的output layer作为输入。最后一层output layer司机哦一个multi-class classifier。多少层和多少个neuron只可以靠经验和直觉&lt;/p&gt;
&lt;h3 id=&quot;goodness-of-a-function-cross-entropy&quot;&gt;goodness of a function cross entropy&lt;/h3&gt;
&lt;p&gt;这一步就要找loss function拉，因为最后一层是multi class classifier,所以跟上节课的一样对y跟y hat用cross entropy就可以了。
&lt;img src=&quot;/img/deepLearning/loss.png&quot; alt=&quot;loss&quot; /&gt;&lt;/p&gt;
&lt;h3 id=&quot;pick-the-best-function&quot;&gt;pick the best function&lt;/h3&gt;
&lt;p&gt;emmmmmm……gradient descent&lt;/p&gt;
</description>
        <pubDate>Mon, 14 Jan 2019 00:00:00 +0800</pubDate>
        <link>/machine%20learning/deepLearning.html</link>
        <guid isPermaLink="true">/machine%20learning/deepLearning.html</guid>
        
        <category>ML</category>
        
        
        <category>machine learning</category>
        
      </item>
    
      <item>
        <title>Logistic Regression</title>
        <description>&lt;h2 id=&quot;review&quot;&gt;review&lt;/h2&gt;
&lt;p&gt;老规矩review，这是我看了第一遍之后在回来做的review，蓝瘦×3!&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;linear regression,之前一直记的都是一个参数的linear regression。这里review一下多个参数的function,&lt;script type=&quot;math/tex&quot;&gt;f(x)=\Sigma w_{i}x_{i}&lt;/script&gt;，看清楚了这里的输入x是vector。Loss Function,&lt;script type=&quot;math/tex&quot;&gt;L(w,b)=(\hat y-(w_{i}*x_{i}+b))^{2}&lt;/script&gt;。用 gradient descent 求偏导数update参数,&lt;script type=&quot;math/tex&quot;&gt;w_{i+1}=w_{i}-\eta \frac{\partial f(x)}{\partial w_{i}}\|_{w=w_{i},b=b{i}}&lt;/script&gt; 。看清楚这里的updata过程的对L求偏导的结果&lt;script type=&quot;math/tex&quot;&gt;-2(\hat{y}-f(x))   \frac{\partial f}{\partial w_{i}}&lt;/script&gt;,而&lt;script type=&quot;math/tex&quot;&gt;\frac{\partial f}{\partial w}=x&lt;/script&gt;。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;回忆上次的classification，抽样知道P(c1),P(c2),令p(x|c1)为多维正太分布&lt;script type=&quot;math/tex&quot;&gt;f_{\mu,\Sigma}(x)=\frac{1}{(2\pi)^{\frac{D}{2}}}\frac{1}{\left \| \Sigma \right \|^{\frac{1}{2}}}exp\{-\frac{1}{2}(x-\mu)\Sigma ^{-1}\} (x-\mu)&lt;/script&gt;(note：左边这个公式的sigma是一个绝对值,那是绝对值号应该是一个竖线),此处的covariance&lt;script type=&quot;math/tex&quot;&gt;\Sigma&lt;/script&gt;是矩阵,x &lt;script type=&quot;math/tex&quot;&gt;\mu&lt;/script&gt;都是vector。令两个class的&lt;script type=&quot;math/tex&quot;&gt;\Sigma&lt;/script&gt;一致，求出mean及 covariance,那么gaussian就出来了。对于每一个数据代入函数之后都会得到一个概率p(c|x)，如果大于0.5就是class1否则class2(二元分类)。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;上次classification最后欠下的债，最后的warning of math，以为例行的听不懂第二天的太阳还是会升起来，但是最后的结论很重要，如果我们通过数学在covariance一致的情况下化简一下，发现z是线性的&lt;br /&gt;&lt;script type=&quot;math/tex&quot;&gt;z=\Sigma w_{i}x_{i}&lt;/script&gt;,&lt;script type=&quot;math/tex&quot;&gt;p(c\|x)=\frac{1}{1+e^{-z}}&lt;/script&gt;那么我们可不可以直接找出w和b呢，这就是这节课做的事情。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;discrimination&quot;&gt;discrimination&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;首先我们的function set 跟上一次课用的generative是一致的(covariance一致的时候).&lt;/strong&gt;
&lt;img src=&quot;/img/logisticRegression/functionSet.png&quot; alt=&quot;functionSet&quot; /&gt;
&lt;br /&gt;
然后我们就要training这个function出来了，写出概率的函数&lt;/p&gt;

&lt;p&gt;注意了，一定要理解清楚意义，这个函数f是我们要求的那个概率函数(就是training的那个),图片上面的x跟y是data
&lt;img src=&quot;/img/logisticRegression/logisticGoodness.png&quot; alt=&quot;logisticGoodness&quot; /&gt;
然后做一些数学转换
&lt;img src=&quot;/img/logisticRegression/mathConvert.png&quot; alt=&quot;mathConvert，图片有部分错误等待新图&quot; /&gt;
转换完之后就要用gradient descent做偏微分了，理解下图的公式中字母的意义，L是概率函数，y跟x都是data，n其实是sigma的标号
&lt;img src=&quot;/img/logisticRegression/findBest.png&quot; alt=&quot;findBest&quot; /&gt;
&lt;br /&gt;
那么找出来的结果，我们可以看到update参数的式子跟linear regression的是一样的
&lt;img src=&quot;/img/logisticRegression/outcome.png&quot; alt=&quot;outcome&quot; /&gt;
&lt;img src=&quot;/img/logisticRegression/compare.png&quot; alt=&quot;compare&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;why-onto-square-error&quot;&gt;why onto square error&lt;/h2&gt;

&lt;p&gt;无论&lt;script type=&quot;math/tex&quot;&gt;\hat{y}&lt;/script&gt;是1还是0，距离目标特别远或特别近，偏微分都几乎是0(理论上微分应该大一点，这样速度大),所以用像linear regression一样的Loss function的时候f(x)在接近0或者1的时候都非常的慢跟在target差不多&lt;/p&gt;

&lt;h2 id=&quot;discrimination-vs-generative&quot;&gt;discrimination vs generative&lt;/h2&gt;
&lt;p&gt;前面提到了两者的function set 是一致的，显然我们通过两种方法找到的w跟b 是不一样的。在discrimination中我们对w和b是没有任何假设的，而我们在generative中是由假设的，例如我们把它假设为gaussian。二在实际中discrimination通常比generative结果要好。老师举了一个naive bays的例子说为什么，但是我觉得这样是因为认为的用naive bays，这个例子没有说服力。
&lt;img src=&quot;/img/logisticRegression/naive.png&quot; alt=&quot;naive&quot; /&gt;
&lt;br /&gt;&lt;/p&gt;
&lt;h2 id=&quot;benefits-of-generative-model&quot;&gt;benefits of generative model&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;当只有很少data的时候可以依靠generative的”脑补”能力(因为他要假设概率模型)来提高准确率&lt;/li&gt;
  &lt;li&gt;more robust to noise&lt;/li&gt;
  &lt;li&gt;说是p(c)跟P(x|c)可以分开算，这里视频里面老师举的例子没有出现，估计是现场有其他的设备展示(蓝瘦！)。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;multi-class-classificatin&quot;&gt;multi-class classificatin&lt;/h2&gt;

&lt;p&gt;如下图，在多个class的时候呢。我们用softmax就可以直接求到概率&lt;script type=&quot;math/tex&quot;&gt;\hat{y}=&lt;/script&gt;\p(c1|x),
&lt;img src=&quot;/img/logisticRegression/softmax.png&quot; alt=&quot;softmax&quot; /&gt;
老师说从一开始假设Gaussian而且共用covariance matrix出发可以推导出来这个式子，然而他没有讲怎么推导。然后就有把cross entropy的式子丢出来了，没有推导多个class的情况二是直接给出来 (cross entropy的表达式)。也就是说p(c|x)=&lt;script type=&quot;math/tex&quot;&gt;y_{i} =\frac{e^{z_{i}}}{\sum_{j=1}^{n} e^{z_{j}}}&lt;/script&gt;。由feature data求得的&lt;script type=&quot;math/tex&quot;&gt;y_{i}&lt;/script&gt;跟data&lt;script type=&quot;math/tex&quot;&gt;\hat{y}&lt;/script&gt;cross entropy之后就可以等到概率L的表达式.
&lt;img src=&quot;/img/logisticRegression/multiCrossEntropy.png&quot; alt=&quot;multiCrossEntropy&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;limitation-of-logistic-regression&quot;&gt;limitation of logistic regression&lt;/h2&gt;

&lt;p&gt;如题啊。如图，一条线无法分开这两个class，可以通过feature transformation 来解决。这是用来引出下节课要讲的内容deep learning。
&lt;img src=&quot;/img/logisticRegression/limitation.png&quot; alt=&quot;limitation&quot; /&gt;
&lt;strong&gt;终于写完了好他妈长&lt;/strong&gt;&lt;/p&gt;
</description>
        <pubDate>Sat, 12 Jan 2019 00:00:00 +0800</pubDate>
        <link>/machine%20learning/LogisticRegression.html</link>
        <guid isPermaLink="true">/machine%20learning/LogisticRegression.html</guid>
        
        <category>ML</category>
        
        
        <category>machine learning</category>
        
      </item>
    
      <item>
        <title>classification</title>
        <description>&lt;h2 id=&quot;如果当作regression来做存在的问题&quot;&gt;如果当作regression来做存在的问题&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;由于regression的使ef尽可能接近曲线的特性，会被一些非常正确的点,如图显然右边regression得到的结果是不好的&lt;/li&gt;
  &lt;li&gt;如果用数字表示某类，而用regression来做，由于数字接近的class在regression上面意味着它们有某种关系，而这是不一定的，因为数字是我们人为设定的。
&lt;img src=&quot;/img/classification/tooCorrect.png&quot; alt=&quot;tooCorrect&quot; /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;ideal-alternative&quot;&gt;ideal alternative&lt;/h2&gt;
&lt;p&gt;尝试用regression，但是这存在很多问题。
虽然可以用perceptron或SVM，但目前只学过gradient descent 我们不会training function
&lt;img src=&quot;/img/classification/idealAlternative.png&quot; alt=&quot;idealAlternative&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;generative-model&quot;&gt;generative model&lt;/h2&gt;
&lt;p&gt;然后介绍正确的做法了，就像是用贝叶斯公式一样，(假设是二元分类)如果我们知道p(c1),p(c2)和p(x|c1),p(x|c2)我们就可以求到p(c1|x)和p(c2|x)。
由training data可以得到,P(c1) P(c2) (如data中有79个水系小精灵，61个普通系，那么P(c1)=79/140)。
&lt;img src=&quot;/img/classification/generativeModel.png&quot; alt=&quot;generativeModel&quot; /&gt;
然后不同的class的feature服从不同的分布,只要找出这个分布就可以知道P(x|c)，老师用的是正太的概率分布。
&lt;img src=&quot;/img/classification/gaussian.png&quot; alt=&quot;gaussian&quot; /&gt;
然后由极大拟然估计估计先出mean(算出来mean就是均值拉)再求出covariance(对称矩阵).
&lt;img src=&quot;/img/classification/maxiLike.png&quot; alt=&quot;maxiLike&quot; /&gt;
&lt;br /&gt;
&lt;strong&gt;注意图片当中的x是vector(例子中是二维，一个是防御力，一个是特殊防御力)&lt;/strong&gt;
&lt;br /&gt;
&lt;img src=&quot;/img/classification/meanCovariance.png&quot; alt=&quot;meanCovariance&quot; /&gt;
因为二元分类，老师的例子只要判断p(c|x)&amp;gt;0.5就可以分类，然后
&lt;br /&gt;
&lt;strong&gt;老师就gg了，老师就gg了，老师就gg了……，二维结果只有47%，7维只有54%&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;modifying-model&quot;&gt;modifying model&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;老师说两个class都用不同的covariance的话他们的参数太多，那么variance就太大，所以强制让他们的covariance相同(这样子就缩小了model的fucntion set 从而减小了variance，而增大了bias)。为什么可以这么做可以在bishop4.2.2找答案。期望值的计算方法还是跟covariance不一样的时候(54%那个)一样的极大似然估计方法,结果也是均值。而新的covariance是原来的两个covariance的加权平均。最后做出来的结果正确率有73%&lt;/strong&gt;
&lt;img src=&quot;/img/classification/sameCovariance.png&quot; alt=&quot;sameCovariance&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;three-steps&quot;&gt;three steps&lt;/h2&gt;
&lt;p&gt;总结做法，分三部，确定model，也就是贝叶斯公式拉！然后就是定一个class的distribution求出参数确定这个分布(就是这里老师强制各个分类的covariance相等提高了正确率),这样就有P(x|c)拉，加上算一下training data中各个分类的个数就有p(c)拉，就可以作估计了。
&lt;img src=&quot;/img/classification/threeStep.png&quot; alt=&quot;threeStep&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;probability-distribution&quot;&gt;probability distribution&lt;/h2&gt;
&lt;p&gt;model的选择(probability distribution)是人为选择的。但是同样的，简单的distribution的bias大，复杂的variance大。
如果人为去掉各个feature之间的相关性，当作他们独立的话叫naive bayes classifier，但pokemon的例子gg了&lt;/p&gt;

&lt;p&gt;最后又是warning of math的时间了，证明了为什么强制不同的类用一样的covariance之后它的图像是直线(二维中)的。&lt;/p&gt;
</description>
        <pubDate>Fri, 11 Jan 2019 00:00:00 +0800</pubDate>
        <link>/machine%20learning/classification.html</link>
        <guid isPermaLink="true">/machine%20learning/classification.html</guid>
        
        <category>ML</category>
        
        
        <category>machine learning</category>
        
      </item>
    
      <item>
        <title>gradient descent</title>
        <description>&lt;h2 id=&quot;review&quot;&gt;review&lt;/h2&gt;
&lt;p&gt;首先回忆一下什么是gradient descent。为training一个function:f=b+wx我们定义出来一个Loss Function:&lt;img src=&quot;/img/formula/lossFunc.gif&quot; alt=&quot;lossFunc&quot; /&gt;,Loss Function是为了找到Loss最小的参数。
过程中首先init参数，然后&lt;img src=&quot;/img/gradientDescent/GDprocess.png&quot; alt=&quot;GDprocess&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;tip1tuning-lr&quot;&gt;tip1:tuning LR&lt;/h2&gt;
&lt;p&gt;一句话LR别太小或太大
&lt;img src=&quot;/img/gradientDescent/tuningLR.png&quot; alt=&quot;tuningLR&quot; /&gt;&lt;/p&gt;
&lt;h3 id=&quot;adaptive-learging-rate&quot;&gt;adaptive Learging Rate&lt;/h3&gt;
&lt;p&gt;之后是调节LR的方法,LR应该动态改变，给出了两个点:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;开始我们离destination远之后近，所以呢LR要大，之后LR要小&lt;/li&gt;
  &lt;li&gt;不同的参数要不同的LR&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;介绍了adagrad
&lt;img src=&quot;/img/gradientDescent/ada1.png&quot; alt=&quot;ada1.png&quot; /&gt;
&lt;img src=&quot;/img/gradientDescent/ada2.png&quot; alt=&quot;ada2.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;然后提出了一个contradiction，在原来的gradient descent中梯度越大，learning越大，但是在adagrad中呢，就越小。(觉得这里说的不对，应该是这一次之后的LR越小)&lt;/strong&gt;。
&lt;br /&gt;然后老师解释了，为什么要这样。他是从二元二次函数的角度出发的，说adagrad的分母是二次导数的近似。而我觉得这屁关系没有，所以就不写下来了。
&lt;br /&gt;
还有adagrad在最后LR会特别的小，小的令人发指。&lt;/p&gt;

&lt;h2 id=&quot;tip-2-stochastic-gradient-descent&quot;&gt;Tip 2: Stochastic Gradient Descent&lt;/h2&gt;
&lt;p&gt;很简单Gradient Descent每一次更新参数都是用所以的data的偏导，Stochastic则是随机选一个或者按序轮流都可以
&lt;img src=&quot;/img/gradientDescent/stochastic.png&quot; alt=&quot;stochastic.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;tip-3-feature-scaling&quot;&gt;Tip 3: Feature Scaling&lt;/h2&gt;
&lt;p&gt;就是有一些输入的参数特别大的时候，对输入参数进行调整。如果不作调整一些参数影响会过大，调整之后的在图像上更像一个圆形(二维)。
&lt;img src=&quot;/img/gradientDescent/circle.png&quot; alt=&quot;circle.png&quot; /&gt;
下面是调整的方法
&lt;img src=&quot;/img/gradientDescent/featureScaling.png&quot; alt=&quot;featureScaling.png&quot; /&gt;
最后是gradient descent的数学正确性证明了，好像还是挺简单，不赘述。但是要注意一点，gradient descent正确是建立在LR足够小的前提下，着也就说明了开始的时候为什么LR过大会出现我们不喜欢的情况。&lt;/p&gt;
</description>
        <pubDate>Wed, 09 Jan 2019 00:00:00 +0800</pubDate>
        <link>/machine%20learning/gradientDescent.html</link>
        <guid isPermaLink="true">/machine%20learning/gradientDescent.html</guid>
        
        <category>ML</category>
        
        
        <category>machine learning</category>
        
      </item>
    
      <item>
        <title>where error comes</title>
        <description>&lt;h2 id=&quot;明确几点&quot;&gt;明确几点&lt;/h2&gt;
&lt;p&gt;回忆我们上次做的事情，我们根据pokemon的数据选择了一个model然后training一个函数，用这个函数来估计pokemon的CP值。一下称我们的targetFucntion为tf，training出来的函数为ef，
显然才概率的角度出发，ef大多数情况不与tf一致（除了常函数吧）。而我们要想这些error为什么存在，如何解决。而且上次还出现了overFitting的现象。老师给了两个来源一个bias一个variance
&lt;img src=&quot;/img/errorCome/errorCome.png&quot; alt=&quot;twoErrorSource&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;parallel-universe&quot;&gt;parallel Universe&lt;/h2&gt;
&lt;p&gt;这个例子我觉得很契合，想象我们在多个平行宇宙用同一个model来training一个ef，而ef是跟我们手上拿到的trainingData有关的，显然我们的ef就会有误差有自己的分布函数。这是确立model之后error的来源就是variance，可以理解为方差，也就是概率分布那个误差。这是第一个错误来源variance。而且指出简单的model的variance更小，是因为简单的model受到trainingData的影响更小。
像下图，我们选择简单的model，那么平行宇宙的我们training出来的ef是比较集中在一个区域的。因此variance带来的error就较小。
&lt;img src=&quot;/img/errorCome/variance.png&quot; alt=&quot;variance&quot; /&gt;
第二个错误来源是bias,这个错误是来自于我们选择的model,因为复杂的model包含是简单的model的超集，包含了简单的model。简单的model可能并没有把tf包含在内。相应地functionSet大了，variance也就大了，bias小了。
&lt;img src=&quot;/img/errorCome/space.png&quot; alt=&quot;space&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;不同model图像比较&quot;&gt;不同model图像比较&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;黑线是tf，蓝线是ef，红线…就当是平行宇宙吧。&lt;/strong&gt;
可以看到复杂的model曲线分布十分散乱，但数量大时比之简单的model更加逼近tf
&lt;img src=&quot;/img/errorCome/variousModels.png&quot; alt=&quot;variousModels&quot; /&gt;
&lt;br /&gt;
———————————————————————————————————————-
&lt;br /&gt;
&lt;img src=&quot;/img/errorCome/tf.png&quot; alt=&quot;tf&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;which-large&quot;&gt;which Large&lt;/h2&gt;
&lt;p&gt;那么我们什么时候我们的model包含了tf呢？或者说bias和variance哪个更大？
当我们的training出来的ef&lt;strong&gt;不能&lt;/strong&gt;很好地契合trainingData的时候就是underFitting，就是没有把tf包含在fucntionSet中。
当我们的training出来的ef&lt;strong&gt;可以&lt;/strong&gt;很好地契合trainingData，&lt;strong&gt;但是不能fit TestingData&lt;/strong&gt;的时候就是overFitting，就是tf包含在fucntionSet中，但是在给定的model中，我们的trainingData的数量不能把variance降低下来（也就是范围大了，打中红心的几率小了，打到外面几率大），而且我们的ef并没有幸运地命中tf较近的地方&lt;/p&gt;
&lt;h2 id=&quot;deal-with-bias-and-variance&quot;&gt;deal with bias and variance&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;对于bias大，就是model的function小，有两个途径：&lt;/strong&gt;
&lt;br /&gt;
1 是redesign model，2 是加入更多的变量（如pokemon的血量）
两个方法其实都是加大了functionSet
&lt;br /&gt;
&lt;img src=&quot;/img/errorCome/whichLarge.png&quot; alt=&quot;whichLarge&quot; /&gt;
&lt;br /&gt;
&lt;strong&gt;对于variance大，就是function很大，而数据量不足&lt;/strong&gt;
&lt;br /&gt;
1 增加数据量，2 regularization,而regularization会损害bias，因为只包含了比较平滑的曲线，使functionSet变小
&lt;img src=&quot;/img/errorCome/doWithVariance.png&quot; alt=&quot;doWithVariance&quot; /&gt;
那么在给定的数据中，我们就要选择bias与variance的平衡。
&lt;img src=&quot;/img/errorCome/bVv.png&quot; alt=&quot;bVv&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;dont-do-this&quot;&gt;Don’t do this&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;不该做的事&lt;/strong&gt;:
&lt;br /&gt;
选择出来几个model用trainingData trainging出来ef之后，然后比较他们在TestingData上面的error来选择model中的一个。但是因为TestingData身为数据本身是有bias的，TestingData应该仅仅用来test
&lt;img src=&quot;/img/errorCome/notDo.png&quot; alt=&quot;notDo&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;正确做法&quot;&gt;正确做法&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;trainingData分两部分一部分选用来training，另一部分反选择model，然后用全部的data来train这个ef，这时候在publicTestingData上的error才真正反映在privateData上的error
&lt;img src=&quot;/img/errorCome/CrossValid.png&quot; alt=&quot;CrossValid&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;避免某一次分数据带来的错误，nFoldCross,也就是把trainingData分多份，一次用其中一份来做反选model.我在想多次随即分两份数据可不可以呢？
&lt;img src=&quot;/img/errorCome/nFold.png&quot; alt=&quot;nFold&quot; /&gt;&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Tue, 08 Jan 2019 00:00:00 +0800</pubDate>
        <link>/machine%20learning/errorCome.html</link>
        <guid isPermaLink="true">/machine%20learning/errorCome.html</guid>
        
        <category>ML</category>
        
        
        <category>machine learning</category>
        
      </item>
    
      <item>
        <title>linearRegression</title>
        <description>&lt;h2 id=&quot;regression&quot;&gt;regression&lt;/h2&gt;
&lt;p&gt;一个regression就是找一个输出数字的函数。&lt;/p&gt;
&lt;h2 id=&quot;step1set-up-a-model&quot;&gt;step1：set up a model&lt;/h2&gt;
&lt;p&gt;设计一个函数集合用于估计输出，如：&lt;script type=&quot;math/tex&quot;&gt;f(x)=\Sigma w_{i}x_{i}+b&lt;/script&gt;
改变b和&lt;script type=&quot;math/tex&quot;&gt;w_{i}&lt;/script&gt;就是不同的function，属于同一个model&lt;/p&gt;
&lt;h2 id=&quot;step2-goodness-of-function&quot;&gt;step2: goodness of function&lt;/h2&gt;
&lt;p&gt;判断function的好坏，找一组数据作为training data,用loss function衡量function的好坏，输入function输出function的好坏数值L(f)。如：
&lt;script type=&quot;math/tex&quot;&gt;L(w_{i},b)=(\hat{y}-(\Sigma w_{i}x_{i}+b))^{2}&lt;/script&gt;
&lt;!-- ![lossFunc](/img/formula/lossFunc.gif) --&gt;&lt;/p&gt;
&lt;h2 id=&quot;step3-gradient-descent-find-best-function&quot;&gt;step3: gradient descent find Best function&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;/img/linear/bestfunction.png&quot; alt=&quot;bestFunc&quot; /&gt;
&lt;br /&gt;
&lt;strong&gt;介绍了gradient descent的方法&lt;/strong&gt;
&lt;br /&gt;
&lt;strong&gt;说白了就是求导数,逐步逼近导数为零的点&lt;/strong&gt;
&lt;img src=&quot;/img/linear/oneparameter.png&quot; alt=&quot;oneparameter&quot; /&gt;
&lt;strong&gt;两个的时候，求两个偏微分，多个就多个偏微分&lt;/strong&gt;
&lt;img src=&quot;/img/linear/twoparameter.png&quot; alt=&quot;twoparameter&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;gradient-descent-的缺陷&quot;&gt;gradient descent 的缺陷&lt;/h2&gt;
&lt;p&gt;缺陷就十分明显了，偏微分求到的是极值点，不一定是最值点，还会可能是saddlePoint马鞍点，或者是plateau(偏微分近似为0的地方)
&lt;img src=&quot;/img/linear/plateauSaddleLocal.png&quot; alt=&quot;plateauSaddleLocal&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;select-another-model&quot;&gt;select another model&lt;/h2&gt;
&lt;p&gt;为了降低loss，设计新的model(泰勒展开是不是说明函数可以展开成多项式，所以就直接用多项式代替)，如加入x的2次方3次方等。
从下图就可以看出从4次方开始会有overfitting的现象，trainingData的error小而Test就十分的差
&lt;img src=&quot;/img/linear/trainTestError.png&quot; alt=&quot;trainTestError&quot; /&gt;
&lt;strong&gt;所以为了图像更加平滑(这是因为我们都愿意相信平滑的图像更可能符合)我们要regulazation，从新设计lossFunction加入landa&lt;/strong&gt;
&lt;img src=&quot;/img/linear/regulazation.png&quot; alt=&quot;regulazation&quot; /&gt;
&lt;strong&gt;以这里不对b进行调整，因为b与图像平滑与否无关，然后要自己手动调整landa的值&lt;/strong&gt;
&lt;img src=&quot;/img/linear/ajustLanda.png&quot; alt=&quot;ajustLanda&quot; /&gt;&lt;/p&gt;
</description>
        <pubDate>Sat, 05 Jan 2019 00:00:00 +0800</pubDate>
        <link>/machine%20learning/linearRegression.html</link>
        <guid isPermaLink="true">/machine%20learning/linearRegression.html</guid>
        
        <category>ml</category>
        
        
        <category>machine learning</category>
        
      </item>
    
      <item>
        <title>惨痛的系统史</title>
        <description>&lt;h2 id=&quot;第一次伟大的尝试被acer坑惨了&quot;&gt;第一次伟大的尝试被acer坑惨了&lt;/h2&gt;
&lt;p&gt;记得那是学校运动会，身为运动健将的我蹲在宿舍打算为自己的win8找个伴装上一个高比格的centos。直到晚上我才从一堆英文文档中找到答案装上了双系统，两边各开一次确定它们不打架之后安心地睡去了。
然鹅，第二天我的win8只闻其声却一脸黑屏。解决无果只好敲开了曹哥宿舍的门。“啪！”的一下跪下来，曹哥救救我，我电脑爆炸了。然后曹哥果然不负我所托成功装上双系统，……之后win7又黑屏了(看吧，不是我菜,是我们都很菜！我竟然有点小开心)。具体原因至今未知。网上有的说是acer这个系列电脑都有这个问题。反正双系统没有装上，还掉级到了win7（虽然我觉得win7好像比win8好用的样子）。&lt;/p&gt;

&lt;h2 id=&quot;有钱才是爷&quot;&gt;有钱才是爷&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;/img/expressions/meiqian.jpg&quot; alt=&quot;meiqian&quot; /&gt;
直到去年春节之前我都是用的虚拟机。然后买了自己第一个固态，拆了光驱托子，装了双硬盘。原来的机械硬盘装光驱位，固态装原来的硬盘位可以用sata3的接口，在固态上面装了fedora。
然鹅问题又来了，装了fedora之后win7鼠标竟然动不了了。一开始以为是驱动问题，键盘操作下了驱动安装重启发现还真的好了。然鹅问题没有那么简单。每次我切换系统，就是如果我一直不开fedora，win7是没有问题的，只要我开了fedora，再开win7都要重启一次win7鼠标才能动。至于为什么，又多了一个历史未解之谜。em…先凑合吧&lt;/p&gt;
&lt;h2 id=&quot;尴尬的4个分区&quot;&gt;尴尬的4个分区&lt;/h2&gt;
&lt;p&gt;关于mbr，如下图只有4个分区
&lt;br /&gt;
&lt;img src=&quot;/img/mbr/partition.gif&quot; alt=&quot;mbr&quot; /&gt;
而我的机械硬盘windows备份用了一个分区，c盘一个，d一个，还有其他的占了用扩展分区占了一个。4个完完整整。还想装系统，是想多了。无论怎么样mbr的4个都很符合我的穷比风格。&lt;/p&gt;
&lt;h2 id=&quot;拥抱gpt&quot;&gt;拥抱gpt&lt;/h2&gt;
&lt;p&gt;人总是要装逼，呸！人总是要不断追求更高的境界的。在这个人人都用win10的社会，我跟我win7相依为命多年，电脑一开机就被人鄙视。是时候装个win10装点一下门面了。win10就意味着gpt分区。当初曹哥给我装win7用的是mbr，之后我另一个硬盘也只好用mbr（难不成要老夫每次换系统都进一次bios，把legacy换成uefi吗）。所以gpt是必须要有了的。为了避免翻车，我只好在我的固态上面实验（毕竟fedora那时候用的不多装的东西也没多少，重装就是了）。先下载win10，给bios设密码，关掉secureboot，legacy换成uefi,系统刻进u盘。直接在固态clean掉,装上win10没什么意外。这时候我把win7加进启动项开机的时候是有启动win7的，但是却提示缺少什么文件（其实是跨区不行）。上网查了很多，总结几点：&lt;/p&gt;
&lt;blockquote&gt;
  &lt;ol&gt;
    &lt;li&gt;引导程序(如grub)是有文件系统的，也就是说只要我把secureboot关了，把一个shell改名成那个什么uefi文件，这个shell是会被运行的&lt;/li&gt;
    &lt;li&gt;别人都是可以跨硬盘引导，我的win7好像不可以（我也找到了一个跨硬盘引导失败的人写的blog）&lt;/li&gt;
    &lt;li&gt;bootmgr（好像是这个命令，我忘了）可以根据系统添加引导所需要的文件&lt;/li&gt;
    &lt;li&gt;uefi下面win7的恢复分区没有了不会影响系统的运行与启动&lt;/li&gt;
  &lt;/ol&gt;
&lt;/blockquote&gt;

&lt;p&gt;那么方向就有了，既然不可以跨区就双硬盘三驱动。因为我固态还要装fedora，我想保留原生的驱动程序，不敢用grub去引导win10（还记得当年第一次装双驱动的恐惧吗？）。win7的简单，先在win10下保存原来win7的驱动（防止翻车），再直接把原来的引导格掉，换成fat（uefi好像只人这个格式），在win10下把win7引导所需要的文件丢进去。重启f12，找到win7引导，成功开启win7。老样子鼠标动不了，轻车熟路，装驱动，重启一次，ok。这时候win7的破解是没有了的，百度一下破解掉ko。然后刻fedora，直接把fedora的引导装载一个新的分区（我gpt分区就是多任性），简单。
&lt;br /&gt;
现在三座大山
&lt;img src=&quot;/img/boot.jpg&quot; alt=&quot;boot&quot; /&gt;&lt;/p&gt;
&lt;h2 id=&quot;至今三大未解之迷&quot;&gt;至今三大未解之迷&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;一个硬盘双系统为何win7黑屏有开机声音，有声音说明引导是没有问题的，估计也是驱动的问题。鼠标动不了，我可以用键盘装驱动，屏幕不亮…再见&lt;/li&gt;
  &lt;li&gt;为何每次切换系统win7都要重启一次鼠标才能用（win10并不会，win7这个锅要背，可能我之前黑屏也可以重启试试，重启果然很强大）&lt;/li&gt;
  &lt;li&gt;为何我不能跨硬盘引导呢。还要补充一个我fedora升级之后蓝牙用不了，明明驱动都是好的，等以后再找机会求求老卢教我。&lt;/li&gt;
&lt;/ol&gt;
</description>
        <pubDate>Fri, 04 Jan 2019 00:00:00 +0800</pubDate>
        <link>/coding/installOs.html</link>
        <guid isPermaLink="true">/coding/installOs.html</guid>
        
        <category>os</category>
        
        
        <category>coding</category>
        
      </item>
    
      <item>
        <title>crack PD Hack</title>
        <description>&lt;h2 id=&quot;外挂使用&quot;&gt;外挂使用&lt;/h2&gt;
&lt;p&gt;这个外挂是通过网络验证的,要先通过服务器注册,再充值,每次使用登陆通过服务器的验证后才可以使用。&lt;br /&gt;
外挂长这样:
&lt;img src=&quot;/img/pdhack/ui.png&quot; alt=&quot;PDHackUI&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;od分析&quot;&gt;od分析&lt;/h2&gt;
&lt;p&gt;知道了网络验证之后思路就基本确定了,找recv send 这些windowsAPI去&lt;br /&gt;
先打开od载入看看内存&lt;br /&gt;
发现401000那里那个段内存是空的什么也没有&lt;br /&gt;
&lt;img src=&quot;/img/pdhack/m401000.png&quot; alt=&quot;m401000&quot; /&gt;
&lt;br /&gt;
&lt;strong&gt;F9让它跑一下,停下来回来发现代码已经被解压出来了&lt;/strong&gt;
&lt;br /&gt;
&lt;img src=&quot;/img/pdhack/m40release.png&quot; alt=&quot;m40release&quot; /&gt;
先给recv下个断点然后跑起来,断下来的时候看一下函数调用盏
&lt;img src=&quot;/img/pdhack/recvFuncCallStack.png&quot; alt=&quot;recvFuncCallStack&quot; /&gt;
但是这里的调用只是给了一部分是不完整的其实前面还有很多，我也不知道怎么让它显示更多。我们直接在右下角的堆栈里找，没猜错的话我们可以找到一些返回40xxxx的地址
&lt;br /&gt;
果不其然
&lt;img src=&quot;/img/pdhack/stackfind40.png&quot; alt=&quot;stackfind40&quot; /&gt;
&lt;br /&gt;
回车回去
&lt;img src=&quot;/img/pdhack/callRecv.png&quot; alt=&quot;callRecv&quot; /&gt;
现在上下拉拉看看就可以找到相关信息,或者直接搜字符串都可以看见了
&lt;img src=&quot;/img/pdhack/string.png&quot; alt=&quot;string&quot; /&gt;
剩下的就是怎么让跳的问题了，没什么技术可言了
&lt;br /&gt;
还有一个就是这个外挂是用易语言写的直接搜ff55fc5f5e可以来到易语言的按钮事件的入口(你总要按登陆吧)，跟进去也可以找到相关的地方&lt;/p&gt;
&lt;h2 id=&quot;写外挂补丁&quot;&gt;写外挂补丁&lt;/h2&gt;
&lt;p&gt;那么现在问题来了，我难道每次打魔兽都要开一次od？
&lt;br /&gt;
别说我不会脱壳哦，老夫可是会脱upx的男人。除了upx…em&lt;br /&gt;
&lt;img src=&quot;/img/expressions/zhishimangqu.jpg&quot; alt=&quot;zhishimangqu&quot; /&gt;
谁说破解一定要脱壳的，我不是不会只是不需要！！！
这个外挂每次开了之后都有一个界面,那么这个时候代码是一定已经解压出来了的，所以我们可以等它自己把代码解压出来之后再把跳转点改过来就ok了。
其实就是开一个进程调试pdhack，然后模拟od的过程把pdhack的代码改了。&lt;br /&gt;
具体py代码这样子&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import time
from his_debugger_defines import *
msvcrt=cdll.msvcrt
# msvcrt.system(r' start path to pdHack'.encode('gbk'))
kernel32=windll.kernel32
# pid=int(input(&quot;input pid&quot;))
startupinfo=STARTUPINFO()
memset(byref(startupinfo),0,sizeof(startupinfo))
processinformation=PROCESS_INFORMATION()
memset(byref(processinformation),0,sizeof(processinformation))
startupinfo.dwFlags=0x1
startupinfo.wShowWindow=0x1
startupinfo.cb=sizeof(startupinfo)
if kernel32.CreateProcessA(
    r'path to pdHack'.encode('gbk'),
    None,
    None,
    None,
    None,
    0x10,
    None,
    None,
    byref(startupinfo),
    byref(processinformation)
):
    print(&quot;success&quot;)
    kernel32.CloseHandle(processinformation.hThread)
    kernel32.CloseHandle(processinformation.hProcess)
    print(&quot;close&quot;,processinformation.dwProcessId)
    pid=processinformation.dwProcessId
else:
    msvcrt.system(&quot;pause&quot;.encode())
time.sleep(2)
pHandle=kernel32.OpenProcess(PROCESS_ALL_ACCESS,False,pid)
pd=pHandle
def readMemory(ph,address,length):
    data=&quot;&quot;.encode()
    read_buf=create_string_buffer(length)
    count=c_ulong(0)
    if not kernel32.ReadProcessMemory(
            ph,
            address,
            read_buf,
            length,
            byref(count)
        ):
        print(&quot;read memory False&quot;)
        return data
    return data+read_buf.raw
def writeMemory(pd,address,length,data):
    count=c_ulong(0)
    length=len(data)
    c_data=c_char_p(data)
    if not kernel32.WriteProcessMemory(
            pd,
            address,
            c_data,
            length,
            byref(count)
        ):
        print(&quot;write memory false&quot;)
    


# three jmp
address1=0x40476e
address2=0x404794
address3=0x404880
l=6
writeMemory(pd,address1,l,bytes([0x90 for i in range(6)]))
writeMemory(pd,address2,l,bytes([0xeb,0x0e,0x90,0x90,0x90,0x90]))
writeMemory(pd,address3,l,bytes([0x90 for i in range(6)]))

#network
address4=0x4023d0
address5=0x4023bf  
l2=10
writeMemory(pd,address4,l,bytes([0x90 for i in range(6)]))
writeMemory(pd,address5,l2,bytes([0x90 for i in range(l2)]))

# along newwork
address6=0x4053cf
data=[0xB8,0xd5,0x53,0x40,0x00]
data+=[0xc3,50, 48, 52, 48, 51, 52, 0]
writeMemory(pd,address6,len(data),bytes(data))

print(readMemory(pHandle,address1,l))
print(readMemory(pHandle,address2,l))
print(readMemory(pHandle,address3,l))

#40476e   6
#404792   eb 0e 90*4
#404880    6

#40c787 5

# 404713 6
# 40238f  15   
# 4023d0   6

# 4053cf  204034   50 48 52 48 51 52 0

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
</description>
        <pubDate>Thu, 03 Jan 2019 00:00:00 +0800</pubDate>
        <link>/coding/pdHack.html</link>
        <guid isPermaLink="true">/coding/pdHack.html</guid>
        
        <category>crack</category>
        
        <category>code</category>
        
        
        <category>coding</category>
        
      </item>
    
      <item>
        <title>关于这个博客</title>
        <description>&lt;h2 id=&quot;搭建&quot;&gt;搭建&lt;/h2&gt;
&lt;p&gt;博客部署在githubpage，只是把域名指向改了，用的jekyll做的静态网页，在&lt;a href=&quot;http://jekyllthemes.org/&quot;&gt;jekyll Theme&lt;/a&gt;找了个模板改了一下(理解一下我们这些不会前端的)!模板叫NiceBlog比较简洁，作者觉得现在的模板普遍
&lt;strong&gt;over designed&lt;/strong&gt;,所以搞了个比较简单的！&lt;/p&gt;

&lt;h2 id=&quot;目的&quot;&gt;目的&lt;/h2&gt;
&lt;p&gt;做这个博客倒不是希望有多少人回来看我写的东西，只是给自己一个把学习的过程和成果记录下来的地方。让自己有个写文章的地方，给自己写的动力。&lt;strong&gt;只是我以为没有人看，可能一大堆暗恋我的妹子一天上好几次呢！&lt;/strong&gt;
&lt;br /&gt;
估计我以后回走算法的路，所以以后大部分应该会是关于算法的内容，喜欢算法的同学可以多来转转！&lt;/p&gt;
</description>
        <pubDate>Tue, 01 Jan 2019 00:00:00 +0800</pubDate>
        <link>/introduce/jekyll.html</link>
        <guid isPermaLink="true">/introduce/jekyll.html</guid>
        
        <category>jekyll</category>
        
        <category>me</category>
        
        
        <category>introduce</category>
        
      </item>
    
  </channel>
</rss>
