<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>sofiesJian</title>
    <description>Nothing # this means to ignore newlines until &quot;baseurl:&quot;
</description>
    <link>/</link>
    <atom:link href="/feed.xml" rel="self" type="application/rss+xml"/>
    <pubDate>Thu, 25 Jul 2019 10:45:59 +0800</pubDate>
    <lastBuildDate>Thu, 25 Jul 2019 10:45:59 +0800</lastBuildDate>
    <generator>Jekyll v3.8.5</generator>
    
      <item>
        <title>math warning</title>
        <description>&lt;h2 id=&quot;梯度&quot;&gt;梯度&lt;/h2&gt;
&lt;p&gt;从定义一步步出发&lt;/p&gt;
&lt;h3 id=&quot;偏导数&quot;&gt;偏导数&lt;/h3&gt;
&lt;p&gt;所谓偏导数，就是多元函数中，对于一个变量求导数，此时其余变量当作常量，直观地看就是函数在某一点沿着x方向的变化率，也就是说在这一点沿着x方向函数会增大多少。&lt;/p&gt;

&lt;h3 id=&quot;方向导数&quot;&gt;方向导数&lt;/h3&gt;
&lt;p&gt;顾名思义，跟偏导数相似，不过不是仅仅限于某个轴方向。回忆高中的物理分运动的思想，函数沿着某个方向的变化，可以分解成（此处当作3维）xyz三个方向的运动，从上面偏导数可以得到三个轴方向变化率，那么
ds=(dx,dy,dz)分解成三个方向。即&lt;script type=&quot;math/tex&quot;&gt;ds=(dscos\alpha,dscos\beta,dscos\gamma)&lt;/script&gt;
那么f的变化率就是&lt;script type=&quot;math/tex&quot;&gt;ds\cdot(\frac{\partial f}{\partial x},\frac{\partial f}{\partial y},\frac{\partial f}{\partial z})&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;当ds的方向跟三个偏导数组成的方向一致时，那么f的变化率最大。即:
&lt;br /&gt;&lt;script type=&quot;math/tex&quot;&gt;(cos\alpha,cos\beta,cos\gamma)=c\cdot (\frac{\partial f}{\partial x},\frac{\partial f}{\partial y},\frac{\partial f}{\partial z})&lt;/script&gt;&lt;/p&gt;

&lt;p&gt;由此可得到结论约束曲面与该曲面的梯度正交，例如：&lt;br /&gt;
g(x)=0此处x为矢量，可见g(x)是常量即函数值不变，即沿着该曲面的切面方向与各个方向的偏导数的内积为0，即该曲面的切面方向与梯度(与各个方向的偏导数方向一样)内积为0，故正交。&lt;/p&gt;
</description>
        <pubDate>Thu, 25 Jul 2019 00:00:00 +0800</pubDate>
        <link>/watermelon/mathWarning.html</link>
        <guid isPermaLink="true">/watermelon/mathWarning.html</guid>
        
        <category>math</category>
        
        <category>ML</category>
        
        
        <category>waterMelon</category>
        
      </item>
    
      <item>
        <title>novel spider 2nd</title>
        <description>&lt;h2 id=&quot;analysis&quot;&gt;analysis&lt;/h2&gt;
&lt;p&gt;爬下面这个小说&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;http://big5.quanben5.com/n/zhongshengzhichaojifuerdai/xiaoshuo.html&quot;&gt;http://big5.quanben5.com/n/zhongshengzhichaojifuerdai/xiaoshuo.html&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;一开始直接xpath一写就搞定很开心，但是发现每一章小说都只有前面一半。打开其中一章的html，F12，然后查看网络，刷新。
&lt;br /&gt;
第一个就是&lt;strong&gt;get http://big5.quanben5.com/n/yidaoguantu/25859.html&lt;/strong&gt;
&lt;br /&gt;
发现返回的html文档中小说内容确实只有一半，往下找看到有一个post请求，返回的就是下一半小说的内容，然后看他的参数。&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pinyin	yidaoguantu
content_id	25859
sky	1b76786fcfca2a471a8fc4463513f5d8
t	1551849855
_type	ajax
rndval	1551836182529
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;其中多数参数可以理解含义。
但是有两个看着像是时间戳的东西，和一个叫做sky的参数。不管了先试试是不是时间戳。post之后拿到了一个标准的404。病急乱求医复制sky参数在查看器。找到一段script&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;ajax_post('book','ajax_content','pinyin','yidaoguantu','content_id','25859','sky','1b76786fcfca2a471a8fc4463513f5d8','t','1551849855')
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;然后找到了ajax_post的函数描述&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;function ajax_post(){
	var c = arguments[0] ? arguments[0] : '';
	var a = arguments[1] ? arguments[1] : '';
	for (var i=2;i&amp;lt;arguments.length;i=i+2){
		var field_name=arguments[i] ? arguments[i] : '';
		var field_value=arguments[i+1] ? arguments[i+1] : '';
		ajax.setVar(field_name,field_value);
	}
	ajax.setVar('_type','ajax');
	ajax.requestFile =_cms+'/index.php?c='+c+'&amp;amp;a='+a;
	ajax.method='POST';
	ajax.onCompletion = whenCompleted;
	ajax.onError = whenError;
	ajax.runAJAX();
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;但是还是少一个叫rndval的参数,再search ajax可以在&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;script type=&quot;text/javascript&quot; src=&quot;/app_quanben5/view/skin/ajax.js&quot;&amp;gt;&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;找到ajax这个对象的定义&lt;/p&gt;

&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;function ajax(file) {
this.xmlhttp = null;
this.resetData=function(){this.method=&quot;POST&quot;;this.queryStringSeparator=&quot;?&quot;;this.argumentSeparator=&quot;&amp;amp;&quot;;this.URLString=&quot;&quot;;this.encodeURIString=true;this.execute=false;this.element=null;this.elementObj=null;this.requestFile=file;this.vars=new Object();this.responseStatus=new Array(2)};
this.resetFunctions=function(){this.onLoading=function(){};this.onLoaded=function(){};this.onInteractive=function(){};this.onCompletion=function(){};this.onError=function(){};this.onFail=function(){}};
this.reset = function() {this.resetFunctions();this.resetData();};
this.createAJAX=function(){try{this.xmlhttp=new ActiveXObject(&quot;Msxml2.XMLHTTP&quot;)}catch(e1){try{this.xmlhttp=new ActiveXObject(&quot;Microsoft.XMLHTTP&quot;)}catch(e2){this.xmlhttp=null}}if(!this.xmlhttp){if(typeof XMLHttpRequest!=&quot;undefined&quot;){this.xmlhttp=new XMLHttpRequest()}else{this.failed=true}}};
this.setVar = function(name,value){this.vars[name] = Array(value, false);};
this.encVar = function(name,value,returnvars){if(true == returnvars){return Array(encodeURIComponent(name),encodeURIComponent(value));}else{this.vars[encodeURIComponent(name)] = Array(encodeURIComponent(value), true);}}
this.processURLString=function(string,encode){encoded=encodeURIComponent(this.argumentSeparator);regexp=new RegExp(this.argumentSeparator+&quot;|&quot;+encoded);varArray=string.split(regexp);for(i=0;i&amp;lt;varArray.length;i++){urlVars=varArray[i].split(&quot;=&quot;);if(true==encode){this.encVar(urlVars[0],urlVars[1])}else{this.setVar(urlVars[0],urlVars[1])}}}
this.createURLString=function(urlstring){if(this.encodeURIString&amp;amp;&amp;amp;this.URLString.length){this.processURLString(this.URLString,true)}if(urlstring){if(this.URLString.length){this.URLString+=this.argumentSeparator+urlstring}else{this.URLString=urlstring}}this.setVar(&quot;rndval&quot;,new Date().getTime());urlstringtemp=new Array();for(key in this.vars){if(false==this.vars[key][1]&amp;amp;&amp;amp;true==this.encodeURIString){encoded=this.encVar(key,this.vars[key][0],true);delete this.vars[key];this.vars[encoded[0]]=Array(encoded[1],true);key=encoded[0]}urlstringtemp[urlstringtemp.length]=key+&quot;=&quot;+this.vars[key][0]}if(urlstring){this.URLString+=this.argumentSeparator+urlstringtemp.join(this.argumentSeparator)}else{this.URLString+=urlstringtemp.join(this.argumentSeparator)}}
this.runResponse = function() {eval(this.response);}
this.runAJAX=function(urlstring){if(this.failed){this.onFail()}else{this.createURLString(urlstring);if(this.element){this.elementObj=document.getElementById(this.element)}if(this.xmlhttp){var self=this;if(this.method==&quot;GET&quot;){totalurlstring=this.requestFile+this.queryStringSeparator+this.URLString;this.xmlhttp.open(this.method,totalurlstring,true)}else{this.xmlhttp.open(this.method,this.requestFile,true);try{this.xmlhttp.setRequestHeader(&quot;Content-Type&quot;,&quot;application/x-www-form-urlencoded&quot;)}catch(e){}}this.xmlhttp.onreadystatechange=function(){switch(self.xmlhttp.readyState){case 1:self.onLoading();break;case 2:self.onLoaded();break;case 3:self.onInteractive();break;case 4:self.response=self.xmlhttp.responseText;self.responseXML=self.xmlhttp.responseXML;self.responseStatus[0]=self.xmlhttp.status;self.responseStatus[1]=self.xmlhttp.statusText;if(self.execute){self.runResponse()}if(self.elementObj){elemNodeName=self.elementObj.nodeName;elemNodeName.toLowerCase();if(elemNodeName==&quot;input&quot;||elemNodeName==&quot;select&quot;||elemNodeName==&quot;option&quot;||elemNodeName==&quot;textarea&quot;){self.elementObj.value=self.response}else{self.elementObj.innerHTML=self.response}}if(self.responseStatus[0]==&quot;200&quot;){self.onCompletion()}else{self.onError()}self.URLString=&quot;&quot;;break}};this.xmlhttp.send(this.URLString)}}};
this.reset();
this.createAJAX();
}
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;注意这一行，最后一个未知参数找到确实是时间戳
&lt;strong&gt;this.setVar(“rndval”,new Date().getTime());&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;##code&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import reqfun,re
import lxml,time,requests,random
ips=reqfun.getip()
source=r'http://big5.quanben5.com/n/zhongshengzhichaojifuerdai/xiaoshuo.html'
index=r'http://big5.quanben5.com/'
a=reqfun.myget(source,proxies=random.choice(ips))
a.encoding='utf8'
b=lxml.etree.HTML(a.text)
c=b.xpath(r'//ul[@class=&quot;list&quot;]/li/a')
cc=[index+i.attrib['href'] for i in c]
titles=[i.text for i in b.xpath(r'//ul[@class=&quot;list&quot;]/li/a/span')]
headers={
    'User-Agent': 'Mozilla/5.0 (Windows NT 6.1; Win64; x64; rv:56.0) Gecko/20100101 Firefox/56.0',
    'host':'big5.quanben5.com',
    'DNT':'1',
    'Content-Type': 'application/x-www-form-urlencoded'
}
def getText(href):
    ret=r&quot;ajax_post\('book','ajax_content','pinyin','zhongshengzhichaojifuerdai','content_id','(\d\d\d\d)','sky','(.+?)','t','(\d{10})'&quot;
    global headers
    print(&quot;getting params &quot;)
    while True:
        response=reqfun.myget(href,proxies=random.choice(ips))
        if response!=None:
            break
        print(&quot;return None ,sleeping now,rework after 60s&quot;)
        time.sleep(60)
    response.encoding='utf8'
    par=re.findall(ret,response.text)[0]
    ss=&quot;rndval=%s&quot;%(str(int(time.time())+2833)+str(random.randint(100,999)))
    data='pinyin=zhongshengzhichaojifuerdai&amp;amp;content_id=%s&amp;amp;sky=%s&amp;amp;t=%s&amp;amp;_type=ajax&amp;amp;'%par
    data+=ss
    headers['Referer']=href
    while True:
        # response=requests.post(r'http://big5.quanben5.com/index.php?c=book&amp;amp;a=ajax_content',headers=headers,data=data,proxies={'http':'http://127.0.0.1:8080'})
        print(&quot;posting&quot;)
        response=requests.post(r'http://big5.quanben5.com/index.php?c=book&amp;amp;a=ajax_content',headers=headers,data=data,proxies=random.choice(ips))
        if response!=None:
            break
        print(&quot;return None ,sleeping now,rework after 60s&quot;)
        time.sleep(60)
    response.encoding='utf8'
    content=response.text
    content=content.replace('\xa0','')
    content=content.replace('&amp;lt;p&amp;gt;','\n')
    content=content.replace('&amp;lt;/p&amp;gt;','')
    return content
    
def save(title,text,number):
    try:
        with open(r'D:\python\myCode\zuiguizhizheng\重生之超级富二代.txt','a',encoding='utf8')as f:
            f.write('\n'+title+'\n')
            f.write(text)
        print('save sucess'+str(number)+'  '+title)
    except Exception as e:
        print(e,title,number)

num=8
while num&amp;lt;len(cc):
    save(titles[num],getText(cc[num]),num)
    num+=1
    time.sleep(0.2)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

</description>
        <pubDate>Wed, 06 Mar 2019 00:00:00 +0800</pubDate>
        <link>/coding/novelSpider2nd.html</link>
        <guid isPermaLink="true">/coding/novelSpider2nd.html</guid>
        
        <category>spider</category>
        
        <category>coding</category>
        
        
        <category>coding</category>
        
      </item>
    
      <item>
        <title>sudo python package not found</title>
        <description>&lt;h2 id=&quot;problem&quot;&gt;problem&lt;/h2&gt;
&lt;p&gt;由于用scapy发包要用到root权限，发现了问题。直接sudo的话会出现module not found的错误。但是我的却已经安装了scapy的google一下是用sudo之后的模块导入路径与之前不一样。细想也应该是这么个事。因为这些模块都是我普通用户用 &lt;strong&gt;pip3&lt;/strong&gt; &lt;strong&gt;–user&lt;/strong&gt;装的。
&lt;br /&gt;
在普通用户下执行下面的shell命令&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;python3 -c &quot;import sys;print(sys.path)&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;br /&gt;
输出&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;['', '/usr/lib64/python37.zip', '/usr/lib64/python3.7', '/usr/lib64/python3.7/lib-dynload', '/home/jianjian/.local/lib/python3.7/site-packages',  '/usr/local/lib64/python3.7/site-packages', '/usr/local/lib/python3.7/site-packages', '/usr/lib64/python3.7/site-packages', '/usr/lib/python3.7/site-packages']
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;在root用户下执行下面的shell命令&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;python3 -c &quot;import sys;print(sys.path)&quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;['', '/usr/lib64/python37.zip', '/usr/lib64/python3.7', '/usr/lib64/python3.7/lib-dynload', '/usr/local/lib64/python3.7/site-packages', '/usr/local/lib/python3.7/site-packages', '/usr/lib64/python3.7/site-packages', '/usr/lib/python3.7/site-packages']
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h2 id=&quot;solution&quot;&gt;solution&lt;/h2&gt;
&lt;p&gt;在&lt;a href=&quot;https://python3-cookbook.readthedocs.io/zh_CN/latest/c10/p09_add_directories_to_sys_path.html&quot;&gt;python的官方文档&lt;/a&gt;找到一些关于path和import module的说明。
&lt;br /&gt;
我平时装的module都是在 &lt;strong&gt;/home/jianjian/.local/lib/python3.7/site-packages&lt;/strong&gt;这个目录里。在root权限下的python的sys.path是没有这个path的。
我自己在~/.local/lib/python3/site-packages下面是建有.pth文件的。但我又不想把他装到系统级的python解释其里面。想到个方法就是在每个需要运用root权限的py文件的头两行就加入两行&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import time,sys
sys.path.append('/home/jianjian/.local/lib/python3.7/site-packages')#  your path to site-packages
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;成功sudo&lt;/p&gt;
</description>
        <pubDate>Sat, 09 Feb 2019 00:00:00 +0800</pubDate>
        <link>/linux/sudoPackage.html</link>
        <guid isPermaLink="true">/linux/sudoPackage.html</guid>
        
        <category>linux</category>
        
        <category>python</category>
        
        
        <category>linux</category>
        
      </item>
    
      <item>
        <title>error with virtual when update python</title>
        <description>&lt;h2 id=&quot;problem&quot;&gt;problem&lt;/h2&gt;
&lt;p&gt;之前用的fedora28python的版本还是3.6的时候建立了一个virtualenv的环境但是在升级fedora的时候，python3也升级了。
导致virtualenv中的python出现问题。&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;error while loading shared libraries: libpython3.6m.so.1.0: cannot open shared object file: No such file or directory
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h2 id=&quot;solve&quot;&gt;solve&lt;/h2&gt;
&lt;p&gt;用ldd查看会发现软连接指向的文件没找到。估计是因为升级旧的连接库就删除掉了。google一下知道是连接库的问题。
&lt;a href=&quot;https://forum.manjaro.org/t/virtualenv-issue-after-update-to-python-3-7/55462/4&quot;&gt;指路&lt;/a&gt;
&lt;br /&gt;
有两种做法&lt;/p&gt;
&lt;h3 id=&quot;replace-old-python&quot;&gt;replace old python&lt;/h3&gt;
&lt;p&gt;That is your issue. Please create a new environment as the given one is still looking for python 3.6. In this case it is your ~/virtualenvs/pelican/bin/python which is looking for the non existing lib-file.
&lt;br /&gt;
Quick fix would be to create a new one and copy the bin/python over and update that broken environment. Always do a backup, though.&lt;/p&gt;

&lt;p&gt;就是用新的python另外建一个virtualenv，把里面的python复制到旧的里面代替它，这样新的就是指向python3.7的连接库了。&lt;/p&gt;
&lt;h3 id=&quot;use-always-copy-or-pyenv&quot;&gt;use –always-copy or pyenv&lt;/h3&gt;
&lt;p&gt;You could use following parameter when creating your new virtualenv, when you want to decide when it’s time to upgrade your virtualenv to a newer python version.
&lt;br /&gt;
 –always-copy         Always copy files rather than symlinking.
&lt;br /&gt;
但是我的virtualenv用–always-copy会出错google了一顿也没找到答案
Another approach is with pyenv, where you can install different python versions and then with mkvirtualenv you point to a specific python version.
&lt;br /&gt;&lt;/p&gt;

&lt;p&gt;for example:&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;pyenv install 3.6.6 
mkvirtualenv -p ~/.pyenv/versions/3.6.6/bin/python testenv     
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
</description>
        <pubDate>Thu, 07 Feb 2019 00:00:00 +0800</pubDate>
        <link>/linux/virtualenv.html</link>
        <guid isPermaLink="true">/linux/virtualenv.html</guid>
        
        <category>linux</category>
        
        <category>python</category>
        
        
        <category>linux</category>
        
      </item>
    
      <item>
        <title>novel spider</title>
        <description>&lt;h2 id=&quot;劳模&quot;&gt;劳模&lt;/h2&gt;
&lt;p&gt;过了一年回到家。发现一件惊悚的事情。我妈竟然用手机看小说。更惊悚的是她在微信公众号看了。这中公众号多如牛毛，其实都不是原创，都是从别人那里爬下来，然后让这群傻逼大妈有钱的充钱买没钱的来签到。更更家惊悚的是老妈竟然 &lt;strong&gt;连续&lt;/strong&gt;&lt;strong&gt;连续&lt;/strong&gt;&lt;strong&gt;连续&lt;/strong&gt; 签到了 &lt;strong&gt;200&lt;/strong&gt; &lt;strong&gt;200&lt;/strong&gt; &lt;strong&gt;200&lt;/strong&gt; 多天。我拿过来一看还是那种不太健康的言情小说。我的天啊都100多斤的人了，还有一颗少女心稳重点ok？看着她的连续200多天签到我都于心不忍。&lt;/p&gt;

&lt;h2 id=&quot;spider&quot;&gt;spider&lt;/h2&gt;
&lt;p&gt;一般小说的网页结构都比较简单。就是一个目录，目录下面就是第几张第几张。&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;source=r'https://www.kanshu.la/75/75996/'
a=reqfun.myget(source)
a.encoding='utf8'
b=lxml.etree.HTML(a.text,parser=lxml.etree.HTMLParser())#用HTMLParser的容错能力强
c=b.xpath(r'/html/body/div[1]/div[5]/div[2]/div/dl/dd/a')#xpath直接用浏览器F12 copy下来copy自己的正确的
cc=[index+i.attrib['href'] for i in c][14:]#拿到标签的href属性就可以组合成每一章小说的连接了
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;拿到没一章的连接之后，直接打开xpath把title跟内容拿下来就可以了&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def getText(href,titleXpath,contentXpath):
    response=reqfun.myget(href)
    response.encoding='utf8'
    #用HTMLParser 的容错性比较高
    lt=lxml.etree.HTML(response.text,parser=lxml.etree.HTMLParser())
    title=lt.xpath(titleXpath)[0].text
    content=lt.xpath(contentXpath)[0].xpath('string(.)')
    return (title,content)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;然后就是保存，注意可能有一些字符的无法decode的，如果有就直接replace成’‘就可以了&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;def save(title,text,number,filePath):
    try:
        with open(filePath,'a',encoding='utf8')as f:
            f.write('\n'+title+'\n')
            f.write(text)
        print('save sucess'+str(number)+'  '+title)
    except Exception as e:
        print(e,title,number)
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h2 id=&quot;code&quot;&gt;code&lt;/h2&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;import reqfun
import lxml
def getText(href,titleXpath,contentXpath):
    response=reqfun.myget(href)
    response.encoding='utf8'
    #用HTMLParser 的容错性比较高
    lt=lxml.etree.HTML(response.text,parser=lxml.etree.HTMLParser())
    title=lt.xpath(titleXpath)[0].text
    content=lt.xpath(contentXpath)[0].xpath('string(.)')
    return (title,content)
    
def save(title,text,number,filePath):
    try:
        with open(filePath,'a',encoding='utf8')as f:
            f.write('\n'+title+'\n')
            f.write(text)
        print('save sucess'+str(number)+'  '+title)
    except Exception as e:
        print(e,title,number)


def download(source,hxp,txp,cxp,fp):
    source=r'https://www.kanshu.la/75/75996/'
    index=r'https://www.kanshu.la/'
    a=reqfun.myget(source)
    a.encoding='utf8'
    b=lxml.etree.HTML(a.text,parser=lxml.etree.HTMLParser())
    # c=b.xpath(r'/html/body/div[1]/div[5]/div[2]/div/dl/dd/a')
    c=b.xpath(hxp)
    cc=[index+i.attrib['href'] for i in c][14:]
    num=0
    while num&amp;lt;len(cc):
        save(*getText(cc[num],txp,cxp),num,fp)
        num+=1
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
</description>
        <pubDate>Wed, 06 Feb 2019 00:00:00 +0800</pubDate>
        <link>/coding/novelSpider.html</link>
        <guid isPermaLink="true">/coding/novelSpider.html</guid>
        
        <category>spider</category>
        
        <category>coding</category>
        
        
        <category>coding</category>
        
      </item>
    
      <item>
        <title>Hello World</title>
        <description>&lt;h2 id=&quot;安装keras&quot;&gt;安装keras&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;弱鸡不要用centos&lt;/strong&gt;&lt;br /&gt;
&lt;strong&gt;弱鸡不要用centos&lt;/strong&gt;&lt;br /&gt;
&lt;strong&gt;弱鸡不要用centos&lt;/strong&gt;&lt;br /&gt;
一开始用的centos，别提多坑爹了，各种gcc版本低，各种g++链接库不匹配。装完一个又一个，没完没了。直接pip安装tensorflow和keras就可以，只是服务器(ubuntu)没有pip，安装还会缺少某些东西，百度一下就好了。&lt;/p&gt;

&lt;h2 id=&quot;swap&quot;&gt;swap&lt;/h2&gt;
&lt;p&gt;一开始还是紧紧跟着老师的步伐。用老师的手写字识别的例子。keras上面可以下载数据，昨晚睡觉前用服务器下载就去睡了（服务器：委屈）。在此load进来。接下来又到了喜闻乐见的ctrl c ctrl v 时间了。照着视频敲。
&lt;br /&gt;
好景不长啊！从mnist down下来的数据是二维数组不可以直接用。要先换为一维数组。本来想在py上换了保存下来的。但python会自己被kill掉，百度一下发现是因为py占用内存过高。用的腾讯学生版服务器内存就2g，free看看发现没有swap分区，建个文件分区&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;dd if=/dev/zero of=~/swapfile bs=1M count=1024
mkswap ~/swapfile
swapon /root/swapfile
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;h2 id=&quot;hello-world&quot;&gt;hello world&lt;/h2&gt;

&lt;p&gt;然后用代码换一下保存成numpy数组&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from keras.layers import Dense,Activation
from keras.models import Sequential,model_from_json
import keras
import numpy as np
def func(xtrain,ytrain,name):
    xx=[]
    for i in xtrain:
        temp=[]
        for ii in i:
            temp+=list(ii)
        xx.append(temp)
    xxx=np.array(xx,np.uint8)
    del xx
    yy=[]
    for i in ytrain:
        temp=[0 for ii in range(10)]
        temp[i]=1
        yy.append(temp)
    yyy=np.array(yy,np.uint8)
    np.save('x'+name+'.npy',xxx)
    np.save('y'+name+'.npy',yyy)
    print(&quot;save success&quot;)
(xtr,ytr)=keras.datasets.mnist.load_data()[0]
func(xtr,ytr,'train')
(xtr,ytr)=keras.datasets.mnist.load_data()[1]
func(xtr,ytr,'test')
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;接下来training出来结果保存就ok&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;from keras.layers import Dense,Activation
from keras.models import Sequential,model_from_json
import keras
import numpy as np
xxx=np.load('xtrain.npy')
yyy=np.load('ytrain.npy')
model=keras.models.Sequential()
model.add(Dense(input_dim=28*28,output_dim=500))
model.add(Activation('sigmoid'))
model.add(Dense(output_dim=500))
model.add(Activation('sigmoid'))
model.add(Dense(output_dim=10))
model.add(Activation('softmax'))
model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])
model.fit(xxx,yyy,batch_size=60,epochs=30)
json_string = model.to_json()
try:
    with open(r'/home/ubuntu/my_model_architecture.json','w') as f:
        f.write(json_string)
    model.save_weights(r'/home/ubuntu/my_model_weights.h5')
except Exception as e:
    with open(r'/home/ubuntu/exception','w')as f:
        f.write(str(e))
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;loadModel&lt;/p&gt;
&lt;div class=&quot;highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keras&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;loadModel&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;():&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;keras&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;models&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model_from_json&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;open&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'my_model_architecture.json'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;).&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;read&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;())&lt;/span&gt; 
    &lt;span class=&quot;k&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'my_model_weights.h5'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;model&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;pp&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;arg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;xt&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;num&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arg&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'1'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;''&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;else&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;'0'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;end&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;''&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
        &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;+=&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;1&lt;/span&gt;
        &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;t&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;%&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;28&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;==&lt;/span&gt;&lt;span class=&quot;m&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
            &lt;span class=&quot;n&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s1&quot;&gt;''&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;之前看一下结果还不错，就不会去截图来了&lt;/p&gt;
</description>
        <pubDate>Tue, 05 Feb 2019 00:00:00 +0800</pubDate>
        <link>/machine%20learning/MLhelloWorld.html</link>
        <guid isPermaLink="true">/machine%20learning/MLhelloWorld.html</guid>
        
        <category>ML</category>
        
        
        <category>machine learning</category>
        
      </item>
    
      <item>
        <title>deep learning</title>
        <description>&lt;h2 id=&quot;日常review&quot;&gt;日常review&lt;/h2&gt;
&lt;p&gt;插入review，一开始我们要做分类，通过classification知道二元分类的时候强行用一样的covariance最终找到的funciton是线性的。之后我们尝试直接找到w，b，而不是先假设概率分布再通过极大拟然估计求分布。之后我们把一个二元分类，之前知道p(c|x)=&lt;script type=&quot;math/tex&quot;&gt;\frac{1}{1+e^{-z}}&lt;/script&gt;而z是线性的。
&lt;img src=&quot;/img/logisticRegression/z.png&quot; alt=&quot;z的表达式&quot; /&gt;
然后f是z的simog就是概率，data的概率相乘通过数学转换等价与于求cross entropy。然后通过gradient descent求最佳的function偏微分之后形式跟linear regression是一致的。之后对于多元分类，(老师没给出推到)说可以通过跟classification一样通过假设一样的covariance matrix，求到p{c|x}就是z做softmax得到的结果y（这里的的y是未知的他只是一个表达式）.最后用loss function也是跟二元的一样做cross entropy,之后就是求偏微分找最好的function了。&lt;/p&gt;

&lt;h2 id=&quot;three-steps&quot;&gt;three steps&lt;/h2&gt;
&lt;p&gt;&lt;img src=&quot;/img/deepLearning/threeSteps.png&quot; alt=&quot;threeSteps&quot; /&gt;&lt;/p&gt;

&lt;h3 id=&quot;define-a-set-of-functions-也就是一个neuron-network&quot;&gt;define a set of functions 也就是一个neuron network&lt;/h3&gt;
&lt;p&gt;把logistic regression（也可以不用logistic）连接在一起，一个logistic regression就是一个neuron，所有连接起来就是一个neuron network。每个logistic regression都有自己的parameter(weight,bias)，所有这些parameter就是neuron network的parameter。至于怎么连接是手动连接的，要自己设计。例如fully connect feedforward network。
&lt;img src=&quot;/img/deepLearning/fullyconnectfeedforwardnetwork.png&quot; alt=&quot;fullyconnectfeedforwardnetwork&quot; /&gt;
我们定好一个neuron network的连接结构也就定好了一个function set，当我们定好了neuron network中每个logistic regression 的parameter ，那么我们的function就定下来了。通常用矩阵来做运算，这样可以用gpu加速。除了输入的data那一层和输出结果的那一层，中间的都是hiddenlayer。hidden对feature加工给最后一层的output layer作为输入。最后一层output layer司机哦一个multi-class classifier。多少层和多少个neuron只可以靠经验和直觉&lt;/p&gt;
&lt;h3 id=&quot;goodness-of-a-function-cross-entropy&quot;&gt;goodness of a function cross entropy&lt;/h3&gt;
&lt;p&gt;这一步就要找loss function拉，因为最后一层是multi class classifier,所以跟上节课的一样对y跟y hat用cross entropy就可以了。
&lt;img src=&quot;/img/deepLearning/loss.png&quot; alt=&quot;loss&quot; /&gt;&lt;/p&gt;
&lt;h3 id=&quot;pick-the-best-function&quot;&gt;pick the best function&lt;/h3&gt;
&lt;p&gt;emmmmmm……gradient descent&lt;/p&gt;
</description>
        <pubDate>Mon, 14 Jan 2019 00:00:00 +0800</pubDate>
        <link>/machine%20learning/deepLearning.html</link>
        <guid isPermaLink="true">/machine%20learning/deepLearning.html</guid>
        
        <category>ML</category>
        
        
        <category>machine learning</category>
        
      </item>
    
      <item>
        <title>Logistic Regression</title>
        <description>&lt;h2 id=&quot;review&quot;&gt;review&lt;/h2&gt;
&lt;p&gt;老规矩review，这是我看了第一遍之后在回来做的review，蓝瘦×3!&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;
    &lt;p&gt;linear regression,之前一直记的都是一个参数的linear regression。这里review一下多个参数的function,&lt;script type=&quot;math/tex&quot;&gt;f(x)=\Sigma w_{i}x_{i}&lt;/script&gt;，看清楚了这里的输入x是vector。Loss Function,&lt;script type=&quot;math/tex&quot;&gt;L(w,b)=(\hat y-(w_{i}*x_{i}+b))^{2}&lt;/script&gt;。用 gradient descent 求偏导数update参数,&lt;script type=&quot;math/tex&quot;&gt;w_{i+1}=w_{i}-\eta \frac{\partial f(x)}{\partial w_{i}}\|_{w=w_{i},b=b{i}}&lt;/script&gt; 。看清楚这里的updata过程的对L求偏导的结果&lt;script type=&quot;math/tex&quot;&gt;-2(\hat{y}-f(x))   \frac{\partial f}{\partial w_{i}}&lt;/script&gt;,而&lt;script type=&quot;math/tex&quot;&gt;\frac{\partial f}{\partial w}=x&lt;/script&gt;。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;回忆上次的classification，抽样知道P(c1),P(c2),令p(x|c1)为多维正太分布&lt;script type=&quot;math/tex&quot;&gt;f_{\mu,\Sigma}(x)=\frac{1}{(2\pi)^{\frac{D}{2}}}\frac{1}{\left \| \Sigma \right \|^{\frac{1}{2}}}exp\{-\frac{1}{2}(x-\mu)\Sigma ^{-1}\} (x-\mu)&lt;/script&gt;(note：左边这个公式的sigma是一个绝对值,那是绝对值号应该是一个竖线),此处的covariance&lt;script type=&quot;math/tex&quot;&gt;\Sigma&lt;/script&gt;是矩阵,x &lt;script type=&quot;math/tex&quot;&gt;\mu&lt;/script&gt;都是vector。令两个class的&lt;script type=&quot;math/tex&quot;&gt;\Sigma&lt;/script&gt;一致，求出mean及 covariance,那么gaussian就出来了。对于每一个数据代入函数之后都会得到一个概率p(c|x)，如果大于0.5就是class1否则class2(二元分类)。&lt;/p&gt;
  &lt;/li&gt;
  &lt;li&gt;
    &lt;p&gt;上次classification最后欠下的债，最后的warning of math，以为例行的听不懂第二天的太阳还是会升起来，但是最后的结论很重要，如果我们通过数学在covariance一致的情况下化简一下，发现z是线性的&lt;br /&gt;&lt;script type=&quot;math/tex&quot;&gt;z=\Sigma w_{i}x_{i}&lt;/script&gt;,&lt;script type=&quot;math/tex&quot;&gt;p(c\|x)=\frac{1}{1+e^{-z}}&lt;/script&gt;那么我们可不可以直接找出w和b呢，这就是这节课做的事情。&lt;/p&gt;
  &lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;discrimination&quot;&gt;discrimination&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;首先我们的function set 跟上一次课用的generative是一致的(covariance一致的时候).&lt;/strong&gt;
&lt;img src=&quot;/img/logisticRegression/functionSet.png&quot; alt=&quot;functionSet&quot; /&gt;
&lt;br /&gt;
然后我们就要training这个function出来了，写出概率的函数&lt;/p&gt;

&lt;p&gt;注意了，一定要理解清楚意义，这个函数f是我们要求的那个概率函数(就是training的那个),图片上面的x跟y是data
&lt;img src=&quot;/img/logisticRegression/logisticGoodness.png&quot; alt=&quot;logisticGoodness&quot; /&gt;
然后做一些数学转换
&lt;img src=&quot;/img/logisticRegression/mathConvert.png&quot; alt=&quot;mathConvert，图片有部分错误等待新图&quot; /&gt;
转换完之后就要用gradient descent做偏微分了，理解下图的公式中字母的意义，L是概率函数，y跟x都是data，n其实是sigma的标号
&lt;img src=&quot;/img/logisticRegression/findBest.png&quot; alt=&quot;findBest&quot; /&gt;
&lt;br /&gt;
那么找出来的结果，我们可以看到update参数的式子跟linear regression的是一样的
&lt;img src=&quot;/img/logisticRegression/outcome.png&quot; alt=&quot;outcome&quot; /&gt;
&lt;img src=&quot;/img/logisticRegression/compare.png&quot; alt=&quot;compare&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;why-onto-square-error&quot;&gt;why onto square error&lt;/h2&gt;

&lt;p&gt;无论&lt;script type=&quot;math/tex&quot;&gt;\hat{y}&lt;/script&gt;是1还是0，距离目标特别远或特别近，偏微分都几乎是0(理论上微分应该大一点，这样速度大),所以用像linear regression一样的Loss function的时候f(x)在接近0或者1的时候都非常的慢跟在target差不多&lt;/p&gt;

&lt;h2 id=&quot;discrimination-vs-generative&quot;&gt;discrimination vs generative&lt;/h2&gt;
&lt;p&gt;前面提到了两者的function set 是一致的，显然我们通过两种方法找到的w跟b 是不一样的。在discrimination中我们对w和b是没有任何假设的，而我们在generative中是由假设的，例如我们把它假设为gaussian。二在实际中discrimination通常比generative结果要好。老师举了一个naive bays的例子说为什么，但是我觉得这样是因为认为的用naive bays，这个例子没有说服力。
&lt;img src=&quot;/img/logisticRegression/naive.png&quot; alt=&quot;naive&quot; /&gt;
&lt;br /&gt;&lt;/p&gt;
&lt;h2 id=&quot;benefits-of-generative-model&quot;&gt;benefits of generative model&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;当只有很少data的时候可以依靠generative的”脑补”能力(因为他要假设概率模型)来提高准确率&lt;/li&gt;
  &lt;li&gt;more robust to noise&lt;/li&gt;
  &lt;li&gt;说是p(c)跟P(x|c)可以分开算，这里视频里面老师举的例子没有出现，估计是现场有其他的设备展示(蓝瘦！)。&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;multi-class-classificatin&quot;&gt;multi-class classificatin&lt;/h2&gt;

&lt;p&gt;如下图，在多个class的时候呢。我们用softmax就可以直接求到概率&lt;script type=&quot;math/tex&quot;&gt;\hat{y}=&lt;/script&gt;\p(c1|x),
&lt;img src=&quot;/img/logisticRegression/softmax.png&quot; alt=&quot;softmax&quot; /&gt;
老师说从一开始假设Gaussian而且共用covariance matrix出发可以推导出来这个式子，然而他没有讲怎么推导。然后就有把cross entropy的式子丢出来了，没有推导多个class的情况二是直接给出来 (cross entropy的表达式)。也就是说p(c|x)=&lt;script type=&quot;math/tex&quot;&gt;y_{i} =\frac{e^{z_{i}}}{\sum_{j=1}^{n} e^{z_{j}}}&lt;/script&gt;。由feature data求得的&lt;script type=&quot;math/tex&quot;&gt;y_{i}&lt;/script&gt;跟data&lt;script type=&quot;math/tex&quot;&gt;\hat{y}&lt;/script&gt;cross entropy之后就可以等到概率L的表达式.
&lt;img src=&quot;/img/logisticRegression/multiCrossEntropy.png&quot; alt=&quot;multiCrossEntropy&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;limitation-of-logistic-regression&quot;&gt;limitation of logistic regression&lt;/h2&gt;

&lt;p&gt;如题啊。如图，一条线无法分开这两个class，可以通过feature transformation 来解决。这是用来引出下节课要讲的内容deep learning。
&lt;img src=&quot;/img/logisticRegression/limitation.png&quot; alt=&quot;limitation&quot; /&gt;
&lt;strong&gt;终于写完了好他妈长&lt;/strong&gt;&lt;/p&gt;
</description>
        <pubDate>Sat, 12 Jan 2019 00:00:00 +0800</pubDate>
        <link>/machine%20learning/LogisticRegression.html</link>
        <guid isPermaLink="true">/machine%20learning/LogisticRegression.html</guid>
        
        <category>ML</category>
        
        
        <category>machine learning</category>
        
      </item>
    
      <item>
        <title>classification</title>
        <description>&lt;h2 id=&quot;如果当作regression来做存在的问题&quot;&gt;如果当作regression来做存在的问题&lt;/h2&gt;
&lt;ol&gt;
  &lt;li&gt;由于regression的使ef尽可能接近曲线的特性，会被一些非常正确的点,如图显然右边regression得到的结果是不好的&lt;/li&gt;
  &lt;li&gt;如果用数字表示某类，而用regression来做，由于数字接近的class在regression上面意味着它们有某种关系，而这是不一定的，因为数字是我们人为设定的。
&lt;img src=&quot;/img/classification/tooCorrect.png&quot; alt=&quot;tooCorrect&quot; /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h2 id=&quot;ideal-alternative&quot;&gt;ideal alternative&lt;/h2&gt;
&lt;p&gt;尝试用regression，但是这存在很多问题。
虽然可以用perceptron或SVM，但目前只学过gradient descent 我们不会training function
&lt;img src=&quot;/img/classification/idealAlternative.png&quot; alt=&quot;idealAlternative&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;generative-model&quot;&gt;generative model&lt;/h2&gt;
&lt;p&gt;然后介绍正确的做法了，就像是用贝叶斯公式一样，(假设是二元分类)如果我们知道p(c1),p(c2)和p(x|c1),p(x|c2)我们就可以求到p(c1|x)和p(c2|x)。
由training data可以得到,P(c1) P(c2) (如data中有79个水系小精灵，61个普通系，那么P(c1)=79/140)。
&lt;img src=&quot;/img/classification/generativeModel.png&quot; alt=&quot;generativeModel&quot; /&gt;
然后不同的class的feature服从不同的分布,只要找出这个分布就可以知道P(x|c)，老师用的是正太的概率分布。
&lt;img src=&quot;/img/classification/gaussian.png&quot; alt=&quot;gaussian&quot; /&gt;
然后由极大拟然估计估计先出mean(算出来mean就是均值拉)再求出covariance(对称矩阵).
&lt;img src=&quot;/img/classification/maxiLike.png&quot; alt=&quot;maxiLike&quot; /&gt;
&lt;br /&gt;
&lt;strong&gt;注意图片当中的x是vector(例子中是二维，一个是防御力，一个是特殊防御力)&lt;/strong&gt;
&lt;br /&gt;
&lt;img src=&quot;/img/classification/meanCovariance.png&quot; alt=&quot;meanCovariance&quot; /&gt;
因为二元分类，老师的例子只要判断p(c|x)&amp;gt;0.5就可以分类，然后
&lt;br /&gt;
&lt;strong&gt;老师就gg了，老师就gg了，老师就gg了……，二维结果只有47%，7维只有54%&lt;/strong&gt;&lt;/p&gt;

&lt;h2 id=&quot;modifying-model&quot;&gt;modifying model&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;老师说两个class都用不同的covariance的话他们的参数太多，那么variance就太大，所以强制让他们的covariance相同(这样子就缩小了model的fucntion set 从而减小了variance，而增大了bias)。为什么可以这么做可以在bishop4.2.2找答案。期望值的计算方法还是跟covariance不一样的时候(54%那个)一样的极大似然估计方法,结果也是均值。而新的covariance是原来的两个covariance的加权平均。最后做出来的结果正确率有73%&lt;/strong&gt;
&lt;img src=&quot;/img/classification/sameCovariance.png&quot; alt=&quot;sameCovariance&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;three-steps&quot;&gt;three steps&lt;/h2&gt;
&lt;p&gt;总结做法，分三部，确定model，也就是贝叶斯公式拉！然后就是定一个class的distribution求出参数确定这个分布(就是这里老师强制各个分类的covariance相等提高了正确率),这样就有P(x|c)拉，加上算一下training data中各个分类的个数就有p(c)拉，就可以作估计了。
&lt;img src=&quot;/img/classification/threeStep.png&quot; alt=&quot;threeStep&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;probability-distribution&quot;&gt;probability distribution&lt;/h2&gt;
&lt;p&gt;model的选择(probability distribution)是人为选择的。但是同样的，简单的distribution的bias大，复杂的variance大。
如果人为去掉各个feature之间的相关性，当作他们独立的话叫naive bayes classifier，但pokemon的例子gg了&lt;/p&gt;

&lt;p&gt;最后又是warning of math的时间了，证明了为什么强制不同的类用一样的covariance之后它的图像是直线(二维中)的。&lt;/p&gt;
</description>
        <pubDate>Fri, 11 Jan 2019 00:00:00 +0800</pubDate>
        <link>/machine%20learning/classification.html</link>
        <guid isPermaLink="true">/machine%20learning/classification.html</guid>
        
        <category>ML</category>
        
        
        <category>machine learning</category>
        
      </item>
    
      <item>
        <title>gradient descent</title>
        <description>&lt;h2 id=&quot;review&quot;&gt;review&lt;/h2&gt;
&lt;p&gt;首先回忆一下什么是gradient descent。为training一个function:f=b+wx我们定义出来一个Loss Function:&lt;img src=&quot;/img/formula/lossFunc.gif&quot; alt=&quot;lossFunc&quot; /&gt;,Loss Function是为了找到Loss最小的参数。
过程中首先init参数，然后&lt;img src=&quot;/img/gradientDescent/GDprocess.png&quot; alt=&quot;GDprocess&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;tip1tuning-lr&quot;&gt;tip1:tuning LR&lt;/h2&gt;
&lt;p&gt;一句话LR别太小或太大
&lt;img src=&quot;/img/gradientDescent/tuningLR.png&quot; alt=&quot;tuningLR&quot; /&gt;&lt;/p&gt;
&lt;h3 id=&quot;adaptive-learging-rate&quot;&gt;adaptive Learging Rate&lt;/h3&gt;
&lt;p&gt;之后是调节LR的方法,LR应该动态改变，给出了两个点:&lt;/p&gt;
&lt;ol&gt;
  &lt;li&gt;开始我们离destination远之后近，所以呢LR要大，之后LR要小&lt;/li&gt;
  &lt;li&gt;不同的参数要不同的LR&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;介绍了adagrad
&lt;img src=&quot;/img/gradientDescent/ada1.png&quot; alt=&quot;ada1.png&quot; /&gt;
&lt;img src=&quot;/img/gradientDescent/ada2.png&quot; alt=&quot;ada2.png&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;然后提出了一个contradiction，在原来的gradient descent中梯度越大，learning越大，但是在adagrad中呢，就越小。(觉得这里说的不对，应该是这一次之后的LR越小)&lt;/strong&gt;。
&lt;br /&gt;然后老师解释了，为什么要这样。他是从二元二次函数的角度出发的，说adagrad的分母是二次导数的近似。而我觉得这屁关系没有，所以就不写下来了。
&lt;br /&gt;
还有adagrad在最后LR会特别的小，小的令人发指。&lt;/p&gt;

&lt;h2 id=&quot;tip-2-stochastic-gradient-descent&quot;&gt;Tip 2: Stochastic Gradient Descent&lt;/h2&gt;
&lt;p&gt;很简单Gradient Descent每一次更新参数都是用所以的data的偏导，Stochastic则是随机选一个或者按序轮流都可以
&lt;img src=&quot;/img/gradientDescent/stochastic.png&quot; alt=&quot;stochastic.png&quot; /&gt;&lt;/p&gt;

&lt;h2 id=&quot;tip-3-feature-scaling&quot;&gt;Tip 3: Feature Scaling&lt;/h2&gt;
&lt;p&gt;就是有一些输入的参数特别大的时候，对输入参数进行调整。如果不作调整一些参数影响会过大，调整之后的在图像上更像一个圆形(二维)。
&lt;img src=&quot;/img/gradientDescent/circle.png&quot; alt=&quot;circle.png&quot; /&gt;
下面是调整的方法
&lt;img src=&quot;/img/gradientDescent/featureScaling.png&quot; alt=&quot;featureScaling.png&quot; /&gt;
最后是gradient descent的数学正确性证明了，好像还是挺简单，不赘述。但是要注意一点，gradient descent正确是建立在LR足够小的前提下，着也就说明了开始的时候为什么LR过大会出现我们不喜欢的情况。&lt;/p&gt;
</description>
        <pubDate>Wed, 09 Jan 2019 00:00:00 +0800</pubDate>
        <link>/machine%20learning/gradientDescent.html</link>
        <guid isPermaLink="true">/machine%20learning/gradientDescent.html</guid>
        
        <category>ML</category>
        
        
        <category>machine learning</category>
        
      </item>
    
  </channel>
</rss>
